{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b809f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(temperature=0.7, model=\"llama-3.3-70b-versatile\", api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e9390eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class llm_schema(BaseModel):\n",
    "    movie_summary_flag: Literal[\"positive\",\"negative\"]\n",
    "\n",
    "llm_structured_output = llm.with_structured_output(llm_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc0d9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llm_schema(movie_summary_flag='positive')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_structured_output.invoke(\"The movie was great\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b9e790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie_summary_flag': 'positive'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm_structured_output.invoke(\"The movie was great\")\n",
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe23dfd",
   "metadata": {},
   "source": [
    "# CHAIN with Conditional Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd38afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task - 1 [prompt]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie review evaluator.\"),\n",
    "    (\"human\", \"Please categorize the movie review as positive or negative : {input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc1134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task - 2 [LLM]\n",
    "\n",
    "llm_structured_output = llm.with_structured_output(llm_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a3093e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task - 3 [Custom Runnable]\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def pydantic_json(input:llm_schema)-> str:\n",
    "    \n",
    "    return input.model_dump()['movie_summary_flag']\n",
    "\n",
    "pydantic_json_lambda = RunnableLambda(pydantic_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af691e9",
   "metadata": {},
   "source": [
    "### Conditional Chain 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d616ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task - 1 [prompt]\n",
    "\n",
    "linkedin_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a LinkedIn post generator.\"),\n",
    "    (\"human\", \"Create a post for the following text for LinkedIn : {text}\")\n",
    "])\n",
    "\n",
    "# task - 2 [LLM]\n",
    "\n",
    "llm = ChatGroq(temperature=0.7, model=\"llama-3.3-70b-versatile\", api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "# task - 3 [Str parser]\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain_linkedin = linkedin_prompt | llm | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e4193",
   "metadata": {},
   "source": [
    "### Conditional Chain 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f059b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnableBranch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75483d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insta_chain(text:str):\n",
    "\n",
    "    # task - 1 [prompt]\n",
    "    insta_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a Instagram post generator.\"),\n",
    "        (\"human\", \"Create a post for the following text for Instagram : {text}\")\n",
    "        ])\n",
    "\n",
    "    # task - 2 [LLM]\n",
    "    llm = ChatGroq(temperature=0.7, model=\"llama-3.3-70b-versatile\", api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "    # task - 3 [Str parser]\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    chain_insta = insta_prompt | llm | parser\n",
    "\n",
    "    result = chain_insta.invoke(text)\n",
    "\n",
    "    return result\n",
    "\n",
    "insta_chain_runnable = RunnableLambda(insta_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7fec94",
   "metadata": {},
   "source": [
    "## Final Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "520e4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_chain = RunnableBranch(\n",
    "    (lambda x: \"positive\" in x, chain_linkedin),\n",
    "    insta_chain_runnable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f433f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_orchestrator = prompt_template | llm_structured_output | pydantic_json_lambda | conditional_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3474f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a LinkedIn post for the theme \"positive\":\\n\\n**Spread Positivity in the Workplace!**\\n\\nAs we go about our day, it\\'s easy to get caught up in stress and negativity. But I want to remind everyone that a positive attitude can make all the difference!\\n\\nWhen we focus on the good, we open ourselves up to new opportunities, build stronger relationships, and achieve greater success. So, let\\'s make a conscious effort to spread positivity in our workplaces and communities.\\n\\nHere are a few ways to do just that:\\n\\n Show appreciation for your colleagues and their hard work\\n Share a kind word or smile with someone who needs it\\n Celebrate each other\\'s wins, no matter how big or small\\n\\nRemember, positivity is contagious! Let\\'s create a ripple effect of kindness and support that inspires those around us.\\n\\nWhat are some ways you spread positivity in your workplace? Share with me in the comments!\\n\\n#PositiveVibes #WorkplaceCulture #MentalHealthMatters #KindnessMatters #SuccessMindset'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_orchestrator.invoke({\"input\": \"I love Lord of the rings\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b8ce2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Sometimes you have to go through the darkness to find the light. Don\\'t let negativity weigh you down, instead use it as a reminder to focus on the positive and rise above. #NegativeVibesDontLast #PositiveMindset #MentalHealthMatters\"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_orchestrator.invoke({\"input\": \"I hate Lord of the rings\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
