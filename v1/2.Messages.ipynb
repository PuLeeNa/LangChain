{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b73b5a",
   "metadata": {},
   "source": [
    "# Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73355f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (1.2.14)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (0.7.5)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langchain-core) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: anyio in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\26\\ai\\langchain\\.venv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6d9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(temperature=0.7, model=\"llama-3.3-70b-versatile\", api_key=os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db73ec7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"**PyTorch** is an open-source machine learning library developed by Facebook's AI Research Lab (FAIR). It is primarily used for building and training deep learning models, particularly in the fields of computer vision, natural language processing, and reinforcement learning.\\n\\n### Key Features of PyTorch\\n\\n* **Dynamic Computation Graph**: PyTorch uses a dynamic computation graph, which allows for more flexibility and ease of use compared to static computation graphs used in other frameworks like TensorFlow.\\n* **Automatic Differentiation**: PyTorch provides automatic differentiation, which simplifies the process of computing gradients and optimizing models.\\n* **Modular Architecture**: PyTorch has a modular architecture, making it easy to build and compose complex models from smaller components.\\n* **Strong GPU Support**: PyTorch has strong support for GPU acceleration, allowing for fast and efficient training of large models.\\n* **Extensive Community**: PyTorch has an extensive and active community, with many pre-built models, tutorials, and examples available.\\n\\n### Advantages of PyTorch\\n\\n* **Ease of Use**: PyTorch is known for its simplicity and ease of use, making it a great choice for beginners and experienced practitioners alike.\\n* **Rapid Prototyping**: PyTorch's dynamic computation graph and automatic differentiation make it ideal for rapid prototyping and experimentation.\\n* **Flexibility**: PyTorch's modular architecture and extensive library of pre-built components make it easy to build and customize complex models.\\n\\n### Use Cases for PyTorch\\n\\n* **Computer Vision**: PyTorch is widely used for computer vision tasks such as image classification, object detection, and segmentation.\\n* **Natural Language Processing**: PyTorch is used for NLP tasks such as language modeling, text classification, and machine translation.\\n* **Reinforcement Learning**: PyTorch is used for reinforcement learning tasks such as game playing and robotics.\\n\\n### Example PyTorch Code\\n```python\\nimport torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\n\\n# Define a simple neural network model\\nclass Net(nn.Module):\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.fc1 = nn.Linear(5, 10)  # input layer (5) -> hidden layer (10)\\n        self.fc2 = nn.Linear(10, 5)  # hidden layer (10) -> output layer (5)\\n\\n    def forward(self, x):\\n        x = torch.relu(self.fc1(x))  # activation function for hidden layer\\n        x = self.fc2(x)\\n        return x\\n\\n# Initialize the model, loss function, and optimizer\\nmodel = Net()\\ncriterion = nn.MSELoss()\\noptimizer = optim.SGD(model.parameters(), lr=0.01)\\n\\n# Train the model\\nfor epoch in range(100):\\n    optimizer.zero_grad()\\n    inputs = torch.randn(10, 5)\\n    labels = torch.randn(10, 5)\\n    outputs = model(inputs)\\n    loss = criterion(outputs, labels)\\n    loss.backward()\\n    optimizer.step()\\n    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\\n```\\nThis code defines a simple neural network model, initializes the model, loss function, and optimizer, and trains the model using stochastic gradient descent.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 669, 'prompt_tokens': 49, 'total_tokens': 718, 'completion_time': 1.415516185, 'completion_tokens_details': None, 'prompt_time': 0.00418817, 'prompt_tokens_details': None, 'queue_time': 0.04930492, 'total_time': 1.419704355}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c77f3-627f-7b22-a83e-f7ed6fea8ce4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 49, 'output_tokens': 669, 'total_tokens': 718})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a AI and ML pro assistant.\"),\n",
    "    HumanMessage(content=\"What is pytorch?\"),\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea9bfb9",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b984b7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='tell me briefly about the city of colombo')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "user_input = input(\"give me a city name?\")\n",
    "\n",
    "dynamic_prompt = PromptTemplate.from_template(\"tell me briefly about the city of {city}\")\n",
    "\n",
    "dynamic_prompt.invoke({\"city\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b51458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Colombo is the commercial capital of Sri Lanka, located on the west coast of the island. It's a bustling metropolis with a rich history, cultural diversity, and a blend of colonial and modern architecture. The city is known for its:\\n\\n* Vibrant markets and shopping centers\\n* Historic landmarks like the Dutch Hospital and the Colombo Fort\\n* Beautiful beaches and waterfront promenades\\n* Delicious cuisine, a mix of Sri Lankan, Indian, and international flavors\\n* Friendly and welcoming people\\n\\nColombo is a great base for exploring the rest of Sri Lanka, with easy access to the country's main attractions and a wide range of accommodation options.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "user_input = input(\"give me a city name?\")\n",
    "\n",
    "dynamic_prompt = PromptTemplate.from_template(\"tell me briefly about the city of {city}\")\n",
    "\n",
    "ready_prompt = dynamic_prompt.invoke({\"city\": user_input})\n",
    "\n",
    "llm.invoke(ready_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aeaecf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Sri Lanka is Sri Jayawardenepura Kotte, although the largest city and commercial capital is Colombo.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"What is the capital of {topic}?\"),\n",
    "])\n",
    "\n",
    "ready_prompt = prompt_template.invoke({\"topic\": \"Sri Lanka\"})\n",
    "\n",
    "llm.invoke(ready_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e59c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
