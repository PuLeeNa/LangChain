{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XeyMIv3Hy_D",
        "outputId": "303524f0-2bff-45a5-af79-c4b473dc79c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.3/333.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.7 requires langchain-core>=1.0.0, but you have langchain-core 0.3.33 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU \\\n",
        "  langchain-core==0.3.33 \\\n",
        "  langchain-groq \\\n",
        "  langchain-community==0.3.16 \\\n",
        "  langsmith==0.3.4 \\\n",
        "  google-search-results==2.4.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or \\\n",
        "    getpass(\"Enter LangSmith API Key: \")\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-agents\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O28VGTKuKxQC",
        "outputId": "38af359e-dffd-4ae6-c95d-df34e6d5b830"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter LangSmith API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tools"
      ],
      "metadata": {
        "id": "DVe4SWjtM1D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(x: float, y:float) -> float:\n",
        "  \"\"\"Add 'x' and 'y'.\"\"\"\n",
        "  return x + y\n",
        "\n",
        "@tool\n",
        "def multiply(x: float, y:float) -> float:\n",
        "  \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
        "  return x * y\n",
        "\n",
        "@tool\n",
        "def exponentiate(x: float, y:float) -> float:\n",
        "  \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
        "  return x ** y\n",
        "\n",
        "@tool\n",
        "def substract(x: float, y:float) -> float:\n",
        "  \"\"\"Substract 'x' from 'y'.\"\"\"\n",
        "  return y - x"
      ],
      "metadata": {
        "id": "2qDH41ZAL6eG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the @tool decorator our function is turned into a StructuredTool object, which we can see below:"
      ],
      "metadata": {
        "id": "hZ4aFpxgORTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSPmJzDYNqox",
        "outputId": "045aa387-b78b-462f-a4fa-59c33c672487"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x79ee94e80540>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"        # output from the LLM\n",
        "llm_output_dict = json.loads(llm_output_string)   # load as dictionary\n",
        "llm_output_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPB2fDecOTzI",
        "outputId": "ae8b2849-f561-43a0-b79d-f05c9c26b49c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 5, 'y': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exponentiate.func(**llm_output_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uX7KA2cPqjV",
        "outputId": "7629c252-d8b7-4af8-8e24-183fd5561038"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is then passed into the tool function as kwargs (keyword arguments) as indicated by the ** operator - the ** operator is used to unpack the dictionary into keyword arguments."
      ],
      "metadata": {
        "id": "mgLU04ZxQAWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an Agent"
      ],
      "metadata": {
        "id": "vkXOjZ9jQ7cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpful assistant\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])"
      ],
      "metadata": {
        "id": "sWqtg12XP6iT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\") or \\\n",
        "    getpass(\"Enter your GROQ API key: \")\n",
        "\n",
        "llm = ChatGroq(temperature=0.7, model=\"llama-3.3-70b-versatile\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vqaq-mjRnt0",
        "outputId": "def59fa7-7966-41a5-f692-88ea384fe35e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GROQ API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When creating an agent we need to add conversational memory to make the agent remember previous interactions. We'll be using the older **ConversationBufferMemory** class rather than the newer **RunnableWithMessageHistory** — the reason being that we will also be using the older **create_tool_calling_agent** and **AgentExecutor** method and class."
      ],
      "metadata": {
        "id": "38ujjMzWSMMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",        # must align with MessagesPlaceholder variable_name\n",
        "    return_messages=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oclR80u4RviH",
        "outputId": "c78c0050-8f39-425d-8d4d-225329b71b8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1076208803.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will initialize our agent. For that we need:\n",
        "\n",
        "* llm: as already defined\n",
        "* tools: to be defined (just a list of our previously defined tools)\n",
        "* prompt: as already defined\n",
        "* memory: as already defined"
      ],
      "metadata": {
        "id": "Qv30n0f9TA80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "tools = [add, multiply, exponentiate, substract]\n",
        "\n",
        "agent = create_tool_calling_agent(\n",
        "    llm=llm, tools=tools, prompt=prompt\n",
        ")"
      ],
      "metadata": {
        "id": "gIK_bGzSS1MG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTWjxFhpbi0n",
        "outputId": "7e73de09-cd58-46f9-92fb-d4cc185f2cbc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.invoke({\n",
        "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
        "    \"chat_history\": memory.chat_memory.messages,\n",
        "    \"intermediate_steps\": []   # agent will append its internal steps here\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcIMb2s4Tg64",
        "outputId": "45643c2c-fecd-475d-f5e4-017c51d2016d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ToolAgentAction(tool='multiply', tool_input={'x': 10.7, 'y': 7.68}, log=\"\\nInvoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '75rrfp463', 'function': {'arguments': '{\"x\":10.7,\"y\":7.68}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 437, 'total_tokens': 460, 'completion_time': 0.065427275, 'completion_tokens_details': None, 'prompt_time': 0.12613622, 'prompt_tokens_details': None, 'queue_time': 0.009263997, 'total_time': 0.191563495}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_43d97c5965', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0c1de128-047a-4586-ad41-1208a222aa49-0', tool_calls=[{'name': 'multiply', 'args': {'x': 10.7, 'y': 7.68}, 'id': '75rrfp463', 'type': 'tool_call'}], usage_metadata={'input_tokens': 437, 'output_tokens': 23, 'total_tokens': 460})], tool_call_id='75rrfp463')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNGjkt2obbRZ",
        "outputId": "3e69d7b2-7e2e-4564-e0f7-067db1a41371"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "M0juTP5HUZv6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lekGmSFRaEMw",
        "outputId": "908bc1c5-1439-444b-cd90-87e69881edb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
        "    \"chat_history\": memory.chat_memory.messages,\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84-TPukDaor2",
        "outputId": "debcba21-63fb-49f1-bd9d-00ac3649a54a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 10.7 multiplied by 7.68 is 82.176.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is 10.7 multiplied by 7.68?',\n",
              " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'The result of 10.7 multiplied by 7.68 is 82.176.'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'82.17599999999999' is tool output and 'The result of 10.7 multiplied by 7.68 is 82.176.' is LLM output\n"
      ],
      "metadata": {
        "id": "oV5rH3Myb3Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory.chat_memory.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqZvedyGa8lC",
        "outputId": "4c8b304c-72d0-4e17-b563-ebf1f0ab6ddb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAXQmPZbcmsJ",
        "outputId": "4ab49171-63e8-4b98-cea9-dddad48529fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}), AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={})]), return_messages=True, memory_key='chat_history')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"My name is puLeeNa\",\n",
        "    \"chat_history\": memory.chat_memory.messages\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMx9UvMVbSZI",
        "outputId": "90f8d124-c444-49a9-b3d8-84d4b07af570"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3mThe result of 10.7 multiplied by 7.68 is 82.176.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'My name is puLeeNa',\n",
              " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='My name is puLeeNa', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'The result of 10.7 multiplied by 7.68 is 82.176.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"What is nine plus 10, minus 4 * 2, to the power of 3\",\n",
        "    \"chat_history\": memory\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-p8p_3OcnmG",
        "outputId": "fc9d82b0-2a71-400d-e538-7651571a4548"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'x': 4, 'y': 2}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `substract` with `{'x': 4, 'y': 19}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m15.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'x': 15, 'y': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m3375.0\u001b[0m\u001b[32;1m\u001b[1;3mFirst, 4 * 2 equals 8. Then, 10 + 9 equals 19, and 19 - 8 equals 11. Lastly, 11 to the power of 3 equals 1331. The answer is 1331.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is nine plus 10, minus 4 * 2, to the power of 3',\n",
              " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='My name is puLeeNa', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='First, 4 * 2 equals 8. Then, 10 + 9 equals 19, and 19 - 8 equals 11. Lastly, 11 to the power of 3 equals 1331. The answer is 1331.', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'First, 4 * 2 equals 8. Then, 10 + 9 equals 19, and 19 - 8 equals 11. Lastly, 11 to the power of 3 equals 1331. The answer is 1331.'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\n",
        "    \"input\": \"What is my name\",\n",
        "    \"chat_history\": memory\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPHSlqc2d_02",
        "outputId": "8741ca98-6b21-419e-e51b-9b1a95c87c0e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'x': 9, 'y': 10}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m19.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'x': 4, 'y': 2}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `substract` with `{'x': 8, 'y': 19}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m11.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'x': 11, 'y': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m1331.0\u001b[0m\u001b[32;1m\u001b[1;3mYour name is PuLeeNa.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is my name',\n",
              " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='My name is puLeeNa', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='The result of 10.7 multiplied by 7.68 is 82.176.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='First, 4 * 2 equals 8. Then, 10 + 9 equals 19, and 19 - 8 equals 11. Lastly, 11 to the power of 3 equals 1331. The answer is 1331.', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='Your name is PuLeeNa.', additional_kwargs={}, response_metadata={})],\n",
              " 'output': 'Your name is PuLeeNa.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SerpAPI Weather Agent"
      ],
      "metadata": {
        "id": "4LfwatZjhdI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\") \\\n",
        "    or getpass(\"Enter your SerpAPI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydv6QwTEetTF",
        "outputId": "7f660b75-323a-4f63-e5da-88cd0409f3d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your SerpAPI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "\n",
        "toolbox = load_tools(tool_names=['serpapi'], llm=llm)"
      ],
      "metadata": {
        "id": "IBVZ4HjDkXkf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "@tool\n",
        "def get_location_from_ip():\n",
        "    \"\"\"Get the geographical location based on the IP address.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(\"https://ipinfo.io/json\")\n",
        "        data = response.json()\n",
        "        if 'loc' in data:\n",
        "            latitude, longitude = data['loc'].split(',')\n",
        "            data = (\n",
        "                f\"Latitude: {latitude},\\n\"\n",
        "                f\"Longitude: {longitude},\\n\"\n",
        "                f\"City: {data.get('city', 'N/A')},\\n\"\n",
        "                f\"Country: {data.get('country', 'N/A')}\"\n",
        "            )\n",
        "            return data\n",
        "        else:\n",
        "            return \"Location could not be determined.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error occurred: {e}\"\n",
        "\n",
        "@tool\n",
        "def get_current_datetime() -> str:\n",
        "    \"\"\"Return the current date and time.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n"
      ],
      "metadata": {
        "id": "U9M2W_pHksLe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"you are a helpful assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])"
      ],
      "metadata": {
        "id": "48r4Ar7ElDfc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = toolbox + [get_current_datetime, get_location_from_ip]\n",
        "\n",
        "agent = create_tool_calling_agent(\n",
        "    llm=llm, tools=tools, prompt=prompt\n",
        ")\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "WEddNEehlVuY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = agent_executor.invoke({\n",
        "    \"input\": (\n",
        "        \"I have a few questions, what is the date and time right now? and How is the weather where I am? Please give me degrees in Celsius\"\n",
        "    )\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoaYa1bfyQtm",
        "outputId": "ef2969d9-b3c1-4d54-8641-36d7cffd519b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_current_datetime` with `{}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m2026-02-02 14:39:23\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_location_from_ip` with `{}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mLatitude: 41.2619,\n",
            "Longitude: -95.8608,\n",
            "City: Council Bluffs,\n",
            "Country: US\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `Search` with `weather in Council Bluffs, US in Celsius`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '-2', 'unit': 'Celsius', 'precipitation': '3%', 'humidity': '94%', 'wind': '2 km/h', 'location': 'Council Bluffs, IA', 'date': 'Monday 8:00 AM', 'weather': 'Partly sunny'}\u001b[0m\u001b[32;1m\u001b[1;3mThe current date and time is February 2, 2026, 2:39 PM. The weather in Council Bluffs, US is partly sunny with a temperature of -2 degrees Celsius, 3% precipitation, 94% humidity, and a wind speed of 2 km/h.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "display(Markdown(out[\"output\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "sS-HqWqYyh0Q",
        "outputId": "35c0528f-bf9d-4a7e-a289-2198ed1f58e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The current date and time is February 2, 2026, 2:39 PM. The weather in Council Bluffs, US is partly sunny with a temperature of -2 degrees Celsius, 3% precipitation, 94% humidity, and a wind speed of 2 km/h."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyl6z7X7zQij"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}